{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "An Invitation to Data Science: Mathematics and Programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM1qBqnlR/C6LxNgF3GseFD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyMW6VAFra9o",
        "colab_type": "text"
      },
      "source": [
        "# An Invitation to Data Science\n",
        "By Akvile Valentukonyte\n",
        "\n",
        "### What is this course?\n",
        "I created this interactive course for NMA Summer Session 2020. The listeners of this course are high-school students with some familiarity with Programming and Algorithms (as taught in NMA curriculum or in school). I will not to assume knowledge of Python or of Mathematics beyond 9th grade level. \n",
        "\n",
        "The course is made up out of four notebooks each covering a different topic. \n",
        "\n",
        "In most other courses you have attended before (not necessarily on Data Science) the difficulty tends to increase like so:\n",
        "\n",
        "![Difficulty 1](https://docs.google.com/drawings/d/e/2PACX-1vSipx640HWChEpP9NaCofStG3Ex0zvp40fa8fpWZyWABK8eSu40pS8mmnDbPudPCt_D00GleyrAzatL/pub?w=614&h=424) \n",
        "\n",
        "In this course the difficulty looks more like this:\n",
        "\n",
        "![Difficulty 2](https://docs.google.com/drawings/d/e/2PACX-1vQi7RQY2L4nfHyue89hldCe_-NyhLhKeJPLLnURdsWL8zwmaeRTGbpDeXHbhfmryOPpyQO_vJ2m2zHL/pub?w=614&h=424)\n",
        "\n",
        "So I hope that everyone can find something for them in this material. However much you do not manage to solve in a couple of hours or get too fustrated to solve - leave it be. You can continue to next notebook and take the rest home as a gift for a future you looking for a nice puzzle.\n",
        "\n",
        "### How to take this course?\n",
        "\n",
        "I hope to make this course as interactive as I can. There sure are a lot of text material - but do not read it as a textbook or a handout. Run code snippets and do exercises scatered around the text. Attempt not only the numbered exercises but also those mentioned in sidenotes or comments, follow new questions that arise as you go through the material. There is no deadline for completing them so you will gain the most by doing them at your own pace and having fun!\n",
        "\n",
        "### Acknowledgements\n",
        "\n",
        "This course is inspired by the many teacher I have had. Most notably Dr. Damon Wischik who introduced me to Data Science and Python during [IB Foundations of Data Science](https://www.cl.cam.ac.uk/teaching/1920/DataSci/) course at the University of Cambridge. I hope to give my own interpretation for all topics but I will borrow examples and exercises from this experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEb6LZ1Y273q",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Mathematics and programming\n",
        "\n",
        "I think people that know how to program have a huge advantage in Mathematics. Sometimes you deal with Mathematics that you know you just have to believe it. Well, not necessarily - programming can help you see and get a feel for it before you get into fuzzy equations with $x$'s and $\\frac{df}{dx}$'s. You can make computer show you big and small examples of theorems and results. We will see lots of examples in this notebook about programming Mathematics and start our experiments with it. In the future, when you encounter a hairy Math I hope that exploring it in code will reveal interesting features that will ultimately lead to solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lHLwcOlkLLf",
        "colab_type": "text"
      },
      "source": [
        "## Python Introduction\n",
        "\n",
        "The programming language we are going to use for this course is Python. It is similar to C++ or Java in a sense that is structured by blocks - there are blocks for if-statements, loops and functions. However its syntax is a little bit different. For one, there is no semicolons - `;` - at the end of the line and currly braces `{}` to wrap the blocks. Even `()` are not necessary to wrap conditional statements. \n",
        "\n",
        "In Python variables do not need a type and can change the type through out the program. That is why you do not need to declare them, just pick a name and use it!\n",
        "\n",
        "Lets see an example:\n",
        "\n",
        "(To run a block of code click start symbol on the left or press **Ctrl + Enter** while inside the block. At first it might take some time to initialise. You can see the state of the program in the top wrapper on the right.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKnTqLCzrN2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51a4e5e8-9adb-432f-92e3-3bfde9af8be6"
      },
      "source": [
        "a = 100\n",
        "b = \"Hello\"\n",
        "c = \", \"\n",
        "a = \"World!\"\n",
        "\n",
        "print(b + c + a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, World!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W4A5atYl1fc",
        "colab_type": "text"
      },
      "source": [
        "Whoa, `a` was an integer and it became a string! This is called *dynamic typing* - exciting stuff but we won't go into this further.\n",
        "\n",
        "The advantage of Python is that the system does not need to see the entire program to run parts of it. So we can build and run a Python program bit by bit - reuse variables and results obtained in previous code blocks. This is very beneficial for experiments - when you do not know what the end result should be. That means - use it for science!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX4d2224l0td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39584a67-fe58-470b-ca47-c27a118ae7c5"
      },
      "source": [
        "d = \"Data Science!\"\n",
        "print(b + c + d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, Data Science!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sql2uqq2nn_z",
        "colab_type": "text"
      },
      "source": [
        "You have just reused `b` and `c` from the previous block. By the way, languages who support this 'bit-by-bit' execution are called *interpreted* where as different languages like C++ and Java are called *compiled*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls0c2gE2qNs0",
        "colab_type": "text"
      },
      "source": [
        "## Logarithms and exponentials\n",
        "\n",
        "This section introduces logarithms and expotentials not as a special mathematical concept but as a tool that you can use in everyday programming tasks. Also, it runs through other python concepts like libraries, lists, if-statements, loops and functions. So put your seatbelts on! \n",
        "\n",
        "The problem we face when marrying Math with Computer Science is that for Math microcopic or astronomically large numbers are equally as good as simple numbers like integers or natural numbers. However, programs have to impose limits to how big or small a number can be, so they much prefer everyday numbers like $2$ or $31$. \n",
        "\n",
        "Here is where logarithms come in as a sort of translator from grandiose Math plans to an everyday Programming environment. Logarithms can make small numbers relatively big and large numbers small (it puts normal numbers somewhere in between).\n",
        "\n",
        "**Exercise 1.1.** Lets import `math` library that contains a function for taking logarithms (run the cell with import statement). Then think of a large number and a small number (use any of the simple arithmetic actions `+ - / *` to create them or just slam the keyboard). Put them through the logarithm function and print out the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPfHmntU_Umm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtPLOtp5vUD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "big = # Your big number goes here\n",
        "big_but_small = math.log(big)\n",
        "print(str(big) + \" was converted to \" + str(big_but_small)) # str() tells python to interpret the number as a string\n",
        "\n",
        "# Do a similar sequence of actions for a small number:\n",
        "\n",
        "# Add code here\n",
        "# and here\n",
        "print(str(small) + \" was converted to \" + str(small_but_big))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u7hLv793iGI",
        "colab_type": "text"
      },
      "source": [
        "The inverse (\"undo\") function of logarithm is exponentiation. Try getting your original numbers back using `math.exp`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEawCPgs3tHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "855fdcdf-75b6-4785-d157-5c176e19327b"
      },
      "source": [
        "big_back = math.exp(big_but_small)\n",
        "\n",
        "print(\"The original big number was \" + str(big_back))\n",
        "\n",
        "# Repeat for small number\n",
        "\n",
        "# You code goes here\n",
        "print(\"The original big number was \" + str(small_back))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The original number was 999.9999999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cun2Xv2SweK1",
        "colab_type": "text"
      },
      "source": [
        "I like to play with small numbers and obscure facts. The probability of dying by getting struct by ligthning is roughly $\\frac{1}{180,746}$ and the odds of dying by choking on food is $\\frac{1}{2,618}$. I can calculate the probability that all NMA students in this summer session die by ligthning and that all citizens in Lithuania die by chocking and see which is larger! Lets try it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNF2ly6Oyeyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "aa9be719-d318-4fd6-94ce-24b1478400f8"
      },
      "source": [
        "p_lightning = 1/180746\n",
        "\n",
        "p_NMA_lightning = math.pow(p_lightning, 70) # power function raises the first argument by the second\n",
        "\n",
        "print(\"The probability that Thor unleashes his anger at NMA: \\n\")\n",
        "print(p_NMA_lightning)\n",
        "\n",
        "p_choke = 1/2618\n",
        "\n",
        "p_Lithuania_choke = math.pow(p_choke, 2720284 - 70) # exclude NMA students who died by lightning\n",
        "\n",
        "print(\"\\nThe probability that the population of Lithuania chokes to death: \\n\")\n",
        "print(p_Lithuania_choke)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The probability that Thor unleashes his anger at NMA: \n",
            "\n",
            "0.0\n",
            "\n",
            "The probability that the population of Lithuania chokes to death: \n",
            "\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1qCv-Mj4xxJ",
        "colab_type": "text"
      },
      "source": [
        "Hey, that is not fair! I get zeroes for both probabilities, but surely one is greater than the other. \n",
        "\n",
        "What is going on here? Programs cannot do perfect arithmetic operations, each action loses some precision. You probably saw that by trying to reverse logarithm - unless you got lucky the recovered number was not exactly the original. Similarly here, small (and big) numbers tend to lose precision very quickly. So lets see if logarithms can help.\n",
        "\n",
        "### Aside: logarithm properties\n",
        "\n",
        "In theory we could use any crazy function that does the conversion (big to small and small to big) but logarithms are useful for they properties which are:\n",
        "\n",
        "$$log(a\\times b) = log(a) + log(b)$$\n",
        "\n",
        "$$log(\\frac{a}{b}) = log(a) - log(b)$$\n",
        "\n",
        "So this allows to simplify lots of expressions. And computers can do sum and difference faster than multiplication and division, so these results are very useful!\n",
        "\n",
        "(If this is new to you, do not just believe me - do a small experiment with real numbers to validate this results).\n",
        "\n",
        "Applying these properties, the new numbers look like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80AagZdc7UQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fe64e6a0-6d16-4358-a059-8a31e4c16257"
      },
      "source": [
        "p_lightning = math.log(1/180746)\n",
        "\n",
        "p_NMA_lightning = p_lightning*70\n",
        "\n",
        "print(\"The log probability that Thor unleashes his anger at NMA: \\n\")\n",
        "print(p_NMA_lightning)\n",
        "\n",
        "p_choke = math.log(1/2618)\n",
        "\n",
        "p_Lithuania_choke = p_choke*(2720284 - 70) # exclude NMA students who died by lightning\n",
        "\n",
        "print(\"\\nThe log probability that the population of Lithuania chokes to death: \\n\")\n",
        "print(p_Lithuania_choke)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The log probability that Thor gets angry at NMA: \n",
            "\n",
            "-847.3393606833615\n",
            "\n",
            "The log probability that the population of Lithuania chokes to death: \n",
            "\n",
            "-21408535.589910526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKQHt4l27sb9",
        "colab_type": "text"
      },
      "source": [
        "Wow, real numbers, but what do they mean? Which probability is bigger? Do log numbers follow the ordering of regular numbers?\n",
        "\n",
        "That are some good research questions. Lets try to visualise them. For this we will use a new library `matplotlib.pyplot` but we will give it a shorter name to refer to `plt`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGBKXbRT8hnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4749YWKAQ5j",
        "colab_type": "text"
      },
      "source": [
        "Then we will create some data for ploting. The ploting library takes a set of points - their x and y coordinates and draws a curve through them. We first need a list of x coordinates and the list of the same length of y coordinates. Thankfully creating a list in python is very easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneUheZTApAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x coordinates for points\n",
        "xs = [i/10 for i in range(1,10000)] \n",
        "# This will  do i/10 for each number between 1 and 10000, so we will have \n",
        "# a list that looks like:\n",
        "#   [1/10, 2/10, ..., 10000/10]\n",
        "# Which is the same as:\n",
        "#   [0.1, 0.2, ..., 100] \n",
        "\n",
        "xs # A quick and dirty way to print out some data and see some numbers in the list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn-wv3dfByZj",
        "colab_type": "text"
      },
      "source": [
        "Lists in python otherwise work similarly as arrays in C++. They can be indexed using [] notation. The indices start at 0 and end at `len(a_list) - 1`. Lets create y coordinates that are just log of x's:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcPf4pVaCMtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys = [math.log(x) for x in xs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgNO1mFSCOwj",
        "colab_type": "text"
      },
      "source": [
        "Plotting itself is a fine process with lots of parameters - we won't go into details here, but this code will do the trick."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dc4GuIeCd6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "46a8f094-4552-472e-8351-d6e93e93290b"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(xs, ys)\n",
        "\n",
        "ax.set(xlabel='x', ylabel='y')\n",
        "ax.grid()\n",
        "ax.axhline(y=0, color='orange', linewidth='2')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwJiPYzrCg6n",
        "colab_type": "text"
      },
      "source": [
        "What an interesting graph!\n",
        "\n",
        "Here we see that very small numbers get very big (in the negative direction). Actually, log goes to minus infinity eventually as x gets closer and closer to 0. This warrants a word of warning - logarithm is not defined for negative numbers and 0, so if you get an error playing with logarithms - that is probably why. \n",
        "\n",
        "But for our purpose we can see that logarithms is monotonic - i.e. the bigger the number, the bigger its logarithm. So using this information lets conclude our morbid experiment from earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfrcbmfGDORM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fded3a95-0665-42d2-92bb-40c965073354"
      },
      "source": [
        "if (p_NMA_lightning > p_Lithuania_choke):\n",
        "  print(\"NMA session getting struck by lighting is more likely than Lithuania choking to death\")\n",
        "elif (p_NMA_lightning == p_Lithuania_choke):\n",
        "  print(\"NMA session getting struck by lighting equally as likely to Lithuania choking to death \\n\")\n",
        "  print(\"What are the odds of that!\")\n",
        "else:\n",
        "  print(\"NMA session getting struck by lighting less likely than Lithuania choking to death\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NMA session getting struck by lighting is more likely than Lithuania choking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9IrozrtES5N",
        "colab_type": "text"
      },
      "source": [
        "What an interesting conversation starter at lunch time! \n",
        "\n",
        "Observe how `if:elif:else` block are structured in Python. The program knows that statements are part of the same block by their indentation - so be mindful of that.\n",
        "\n",
        "While we are at it, the loops in python look like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J2Iw-_EIDxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = 0\n",
        "for i in range(10):\n",
        "  s += i\n",
        "  print(\"Partial sum:\" + str(s))\n",
        "\n",
        "while s != 0:\n",
        "  s = (int)(s / 2);\n",
        "  print(\"Integer division of s: \" + str(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhhyk1vJCjp",
        "colab_type": "text"
      },
      "source": [
        "And functions like variables also do not require any types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "397F9cj3JIU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b38fa94-5afb-401c-b680-4a3908913e0b"
      },
      "source": [
        "def sum_upto(n):\n",
        "  if n == 0 :\n",
        "    return 0\n",
        "  return n + sum_upto(n-1)\n",
        "\n",
        "s = sum_upto(9)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXALiEtTBUWo",
        "colab_type": "text"
      },
      "source": [
        "### Final words on the exponential\n",
        "\n",
        "The last section contained more information on logarithms than on their inverse. But exponential is also a useful function. Lets start by looking at its graph. \n",
        "\n",
        "I will admit creating lists for xs using `range` is not very convenient. So I will introduce another mathematical package `numpy` and rename it `np` to save characters. This bundle has a useful function `linspace`. It takes 3 numbers - the start of the interval, the end, and how many equaly spaced number in this interval you are going to need. It will create not exactly a list of these numbers but a numpy array which work basically the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CICad-kiBpbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "exp_xs = np.linspace(-2, 2, 100)\n",
        "\n",
        "exp_xs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr0_hXN9DAgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp_ys = [math.exp(x) for x in exp_xs]\n",
        "\n",
        "#lets add a log curve as well\n",
        "log_xs = np.linspace(0.0001, 2, 100)\n",
        "log_ys = [math.log(x) for x in log_xs]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(exp_xs, exp_ys, label=\"exp\")\n",
        "ax.plot(log_xs, log_ys, label=\"log\")\n",
        "\n",
        "ax.set(xlabel='x', ylabel='y')\n",
        "ax.grid()\n",
        "ax.axvline(x=0, color='grey', linewidth='2')\n",
        "ax.axhline(y=0, color='grey', linewidth='2')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "543C1y67FvTd",
        "colab_type": "text"
      },
      "source": [
        "From this we can see that exponential function is very different from logarithm. For one, it tends to make large numbers even larger! However it too has some useful properties - it turns every number to a positive one while preserving monotonicity. We will see how to use this fact in a later notebook. \n",
        "\n",
        "For now, attempt some exercises bellow. Add a code segment (**Ctrl+M+B**) after each exercise and solve it there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeaRXwgCF1vW",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.2** \n",
        "It is know that $log(n!)$ grows exactly like $n\\times log(n)$ (this result is the basis of why the best possible sorting algorithms are $O(n\\times log(n))$). What that means is that the bigger the n, the more indistinguishable the two functions become. So the line $y = \\frac{n \\times log(n)}{log(n!)} $ should go to 1. Plot the this curve and check if that is so! \n",
        "\n",
        "For mathematically mature: prove the result - i.e. that $$\\lim_{n\\to\\infty} \\frac{n \\times log(n)}{log(n!)} = 1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi_lQHhZQgF6",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.3** Taylor series for exponentials and logs. \n",
        "1. A mathematician tells you that exponential function can be expressed by an infinite polynomial:\n",
        "$$e^x = \\sum_{n=0}^{\\infty} \\frac{x^n}{n!} = 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6}  + ... $$\n",
        "\n",
        "  a) Make a plot of $e^x$ (`math.exp`).\n",
        "\n",
        "  b) Make a plot of the polynomial containing the five members of this infinite sequence, i.e. $y = 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6} + \\frac{x^4}{4!}$\n",
        "  \n",
        "  c) Make a plot of the polynomial containing 7 members. Is the approximation getting better?\n",
        "\n",
        "\n",
        "2. Repeat (a) - (c) but for these series:\n",
        "\n",
        "$$ln(1 + x) = \\sum_{n=0}^{\\infty}(-1)^{n+1} \\frac{x^n}{n} = x - \\frac{x^2}{2} + \\frac{x^3}{3} - ... $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUypGWshkSgl",
        "colab_type": "text"
      },
      "source": [
        "## Probability\n",
        "\n",
        "At its basics, probability is quite an intuitive concept - it describes how often a result occurs when repeating the action that causes it. In school you probably learned how to calculate it. The steps are roughly these:\n",
        "\n",
        "1. Enumerate/calculate all the possible outcomes of an exeperiment. Call the number of outcomes $m$ \n",
        "2. Enumerate all the possible outcomes that you are looking to understand, call it $n$\n",
        "3. Assuming that all outcomes are equally likely, the probability of your event is $\\frac{n}{m}$\n",
        "\n",
        "Even this simple procedure is not obvious to human thinking - a lot of probability usually is like that. For instance, in 2016 one analyst got shamed in the press because he placed D. Trump's victory probability in the US elections at 30 %. We know that  D. Trump won, but we do not know what would happen if the elections were repeated unlimited amount of times, so the poor analyst might be correct. \n",
        "\n",
        "This is all philosophy and mathematics. But what are some computer science tricks to calculate these probabilities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sysGyAdMNoRh",
        "colab_type": "text"
      },
      "source": [
        "### Enumerate the posibilities \n",
        "\n",
        "If the problem is small, then you can use programming to quickly enumerate all posibilities and from them calculate $n$ and $m$. If you are enumerating everything, recursion is particularly useful - who would want to write multiple nested for loops?\n",
        "\n",
        "Consider the following exercise: There are 12 places in total in a parking lot - all arranged in one line. 8 cars have already parked randomly in this lot when Greta drives in. She likes to open her car doors widely, so she only parks if there are two adjacent free places. What is the probability that Greta find a place to park in this parking lot? \n",
        "\n",
        "The first task is to figure out what are the total number of ways 8 cars can be parked in 12 places. Any fool can use \"the choose\" formula $n\\choose m$, but we can make the program count it for us. The only thing to be aware is not to allow two cars park in the same spot.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4VZ9mliWSV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4aecab3a-e67a-4a1c-e6a6-aeaec79abc59"
      },
      "source": [
        "\"\"\"\n",
        "Models parking n cars in the parking lot\n",
        ":param n: how many cars to park\n",
        ":param i: the index of the parking space we are considering\n",
        "\"\"\"\n",
        "def park_cars(n, i):\n",
        "  # Exit condition\n",
        "  if i == 12 : # We have used up all the parking spaces\n",
        "    if n == 0: # No cars left to park - this is a valid parking arrangement\n",
        "      return 1\n",
        "    else : \n",
        "      return 0 # We have not managed to park all the cars\n",
        "  # Otherwise we come to a choice point: we can either use the ith spot and \n",
        "  # place one of the n cars there. Then we need to figure out how many ways\n",
        "  # there are to place the remaining cars.\n",
        "  using_i = park_cars(n-1, i+1) \n",
        "  # Or we can skip this place:\n",
        "  not_using_i = park_cars(n, i+1)\n",
        "  return using_i + not_using_i\n",
        "\n",
        "\n",
        "m = park_cars(8, 0)\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-F-ExzN39vt",
        "colab_type": "text"
      },
      "source": [
        "Now, for $n$ we can use the same recursion scafolding, but also add a model for our parking lot, to remember the assignments we have made!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGjrT35D4HV8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a09a480e-53e6-4814-a72d-1f32c3f15851"
      },
      "source": [
        "parking_lot = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "def is_there_space_for_greta():\n",
        "  for i in range(len(parking_lot) - 1):\n",
        "    if parking_lot[i] == 0 and parking_lot[i+1] == 0:\n",
        "      return 1\n",
        "  return 0\n",
        "\n",
        "\"\"\"\n",
        "Models parking n cars in the parking lot\n",
        ":param n: how many cars to park\n",
        ":param i: the index of the parking space we are considering\n",
        "\"\"\"\n",
        "def calc_n(n, i):\n",
        "  # Exit condition\n",
        "  if i == 12 : # We have used up all the parking spaces\n",
        "    if n == 0: # No cars left to park - this is a valid parking arrangement\n",
        "      # What is left is to find out wheter there are spaces for Greta?\n",
        "      return is_there_space_for_greta()\n",
        "    else : \n",
        "      return 0 # We have not managed to park all the cars\n",
        "  # Use the ith place:\n",
        "  parking_lot[i] = 1\n",
        "  using_i = calc_n(n-1, i+1) \n",
        "  # Or we can skip this place:\n",
        "  parking_lot[i] = 0\n",
        "  not_using_i = calc_n(n, i+1)\n",
        "  return using_i + not_using_i\n",
        "\n",
        "\n",
        "n = calc_n(8, 0)\n",
        "print(n)\n",
        "print(n/m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "0.7454545454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmWibqVXOqiP",
        "colab_type": "text"
      },
      "source": [
        "Recursion is something of an art, but once you get the hang of it you gain an incredible power! \n",
        "\n",
        "### Do an experiment\n",
        "\n",
        "Sometimes it is very hard to come up with a function that can enumerate all the possibilities, yet the setup does not look difficult. In such cases we can do an experiment! That it we model the situation using random numbers and repeat it a lot of times to get a good approximation of the probability. I like this method because it really ties back nicely to the definition of probability - in it we said that probability is all about repeated experiments.\n",
        "\n",
        "Anyway, in this setup, we firstly park 8 cars as in the description. That means, we chose a spot at random and if it is free use it. A library to generate random numbers is called numpy and we will be using it a lot throughout the notebooks! Once we \"parked\" all cars, we can check if in this instance Greta found a place to park and if so count it as an successful experiment - 1. In the end, we run a huge number of experiments (use Python lists for that) then take all the successes and divide by the number of all experiments - it is that simple!\n",
        "\n",
        "One thing to note - when iterating though a list some functions tend to run concurrently, so it is advised to pass the thing you are modeling as an argument rather than make it a global variable!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3hEwb_17QDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31af774a-d3a6-413c-97f7-00b2f8d30aba"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def is_there_space_for_greta(pl):\n",
        "  for i in range(len(pl) - 1):\n",
        "    if pl[i] == 0 and pl[i+1] == 0:\n",
        "      return 1\n",
        "  return 0\n",
        "\n",
        "def park_car(pl):\n",
        "  while True:\n",
        "    place = np.random.choice(range(12)) # choose a number from a list [1, ..., 12]\n",
        "    if pl[place] == 0:\n",
        "      pl[place] = 1\n",
        "      return\n",
        "\n",
        "def run_experiment():\n",
        "  parking_lot = [0,0,0,0,0,0,0,0,0,0,0,0] # reset\n",
        "  for _ in range(8):\n",
        "    park_car(parking_lot)\n",
        "  return is_there_space_for_greta(parking_lot)\n",
        "\n",
        "experiments = [run_experiment() for _ in range(10000)]\n",
        "print(sum(experiments)/len(experiments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmM_IlVtC6Dc",
        "colab_type": "text"
      },
      "source": [
        "That was neat - we just verified the result we got previously. It is always good to do that if it is possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n45eyhWGX3Z",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.4**\n",
        "Design an experiment for the following question:\n",
        "\n",
        "A gambler goes to bet. The dealer has 3 dice, which are fair, meaning that the chance that each face shows up is exactly 1/6.\n",
        "\n",
        "The dealer says: \"You can choose your bet on a number, any number from 1 to 6. Then I'll roll the 3 dice. If none show the number you bet, you'll lose \\$1. If one shows the number you bet, you'll win \\$1. If two or three dice show the number you bet, you'll win \\$3 or \\$5, respectively.\"\n",
        "\n",
        "Is this a lucrative game (you are likely to win more than you loose)? Are you likely to loose more than you win? Or is this a fair game (you win and loose the same)? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7U9rV-ekXm3",
        "colab_type": "text"
      },
      "source": [
        "### Working with probabilities\n",
        "\n",
        "Sometimes the easiest way to solve a puzzle is to actually sit down and work out the probabilities. The approach I like the most is drawing diagrams. I like it because it is a visual way to solve a lot of otherwise tricky exercises. It uses the same idea of enumerating all the possibilities, but in a smarter way.\n",
        "\n",
        "I will illustrate this method with an example and while working through it uncover some useful results in probability theory that will help us later on! \n",
        "\n",
        "Here is a story:\n",
        "\n",
        "> 1% of women at age forty who participate in routine screening have breast cancer.  For a woman with breastcancer, the test comes out postitibe 80% of the time.  9.6% of women without breast cancer will also get positive mammographies.\n",
        "\n",
        "And here is a question you might get asked:\n",
        "\n",
        "> What is the probability for a woman in this age group to have cancer and get a negative test result?\n",
        "\n",
        "Lets draw a little diagram for the entire story. To draw a diagram, you are considering a path each \"character\" (more formally, experiment) could take. Whenever you encounter a random variable (like cancer, test result) you split the path into as many paths as there are possible values. For your own clarity anotate the paths with the value of the variable and its probability. It is useful to add final outcomes to the paths when there is no more random variables that apply to them - just write down the value for each random varaible along the path. In this case there are two variables along the path and each have two possible values, so here is a \"map\" for a woman in question:\n",
        "\n",
        "![](https://docs.google.com/drawings/d/e/2PACX-1vT0BkUbzV56q_bgnaHFa6cgpK_vhzFNqg-i0jRXdzwUrBHyeQj_igjnndjU_MgXN9IF4Qk6wTW3ot2C/pub?w=480&h=360)\n",
        "\n",
        "An important thing to preserve is that each time a path branches off the probabilities on all the paths must sum to one. If they do not there is a path missing as the path should exaust all posibilities! \n",
        "\n",
        "The questions asks us about one possible path in such story - how likely it is for a woman in the agegroup to both have cancer and have the test come out negative?\n",
        "\n",
        "To answer this, we find the desired path and calculate its probability. The probability of a path is the probabilities on its the segment labels multiplied. In this case, the path is:\n",
        "\n",
        "![](https://docs.google.com/drawings/d/e/2PACX-1vSUgaH8v6H83XJwOecDp1pB_vVSxUhTc0l1MSTGX_KdfUUSF9t6NmXFzO5KAnA2JohbCuCVU1m0aK5g/pub?w=960&h=720)\n",
        "\n",
        "And the probability:\n",
        "\n",
        "$$\\mathbb{P}(\\text{cancer }\\textit{and}\\text{ negative}) = 1\\% \\times 20 \\% = \\frac{1\\times 20}{100 \\times 100} = 0.2 \\%$$\n",
        "\n",
        "This is also known as the *and* rule. That is, when we want to calculate the probability of multiple independant events $a_1, a_2, ..., a_n$ happening together we can multiply their probabilities. \n",
        "\n",
        "$$\\mathbb{P}(a_1, a_2, ..., a_n) = \\mathbb{P}(a_1)\\times\\mathbb{P}(a_2)\\times...\\times\\mathbb{P}(a_n)$$\n",
        "\n",
        "You might notice my sloppy derivation here! Actually, the events in our question are not independant - having cancer affects the test outcome. But we adjusted it on the path, so it is still ok. A true pair of independant event would be having cancer *and* wining the lottery.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Plx-2rGxd6H",
        "colab_type": "text"
      },
      "source": [
        "Consider the next question we might be asked:\n",
        "\n",
        "> What is a probability that for a woman the test comes out positive? \n",
        "\n",
        "At first it might be difficult to figure out to path path this relates. So we need to unpack this question first. Since there are two ways the test can come out negative in our outcomes, the question is actually asking:\n",
        "\n",
        "> What is a probability for a woman to develop cancer and get positive test result *or* not to develop cancer and still get positive test results?\n",
        "\n",
        "So we are looking for two paths and they are quite easy to find:\n",
        "\n",
        "![](https://docs.google.com/drawings/d/e/2PACX-1vSh0Hl522TeD4xR3hWEGnTojHxek5s76zs18grIyvT9ph8igNCLEbGo9EJc7-LJehIm3cIZwNkz_VFX/pub?w=960&h=720)\n",
        "\n",
        "Whenever we have paths in paralel we add up their probabilities. This is also known as the *or* rule. It has similar independence requirements and forms like *and* rule, but I won't go into greater detail.\n",
        "\n",
        "$$\\mathbb{P}((\\text{cancer }\\textit{and}\\text{ positive})\\textit{ or }(\\text{no cancer }\\textit{and}\\text{ positive})) = \\mathbb{P}((\\text{cancer }\\textit{and}\\text{ positive})+ \\mathbb{P}(\\text{no cancer }\\textit{and}\\text{ positive}))= 1\\%\\times 80\\%$ + 99\\%\\times 9.6\\% = 10.304 \\%$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMMeV4CRHHTs",
        "colab_type": "text"
      },
      "source": [
        "### Conditional Probability\n",
        "\n",
        "Next and very common question in these situations that you get often asked sounds something like:\n",
        "\n",
        "> Consider a woman of age 40 who took the mammography test. It came out possitive. What is the probability that the woman has breast cancer?\n",
        "\n",
        "This question is so important that I even dedicated an entire subsection for it! \n",
        "\n",
        "To illustrate this question in the diagram, the same diagram as before actually suffices.\n",
        "\n",
        "![](https://docs.google.com/drawings/d/e/2PACX-1vSh0Hl522TeD4xR3hWEGnTojHxek5s76zs18grIyvT9ph8igNCLEbGo9EJc7-LJehIm3cIZwNkz_VFX/pub?w=960&h=720)\n",
        "\n",
        "To reason about it we can think back to our original probability definition - divide the things that you are looking for over all possible things. What is all the possible things in this case? We are only given that the woman's test result is positive, thus there are two scenarios: either the woman has cancer or doesn't. And we already know the probability (i.e. the fraction of cases where) this happens $10.304\\%$. What is the outcome that we are looking for? It is the path where the woman both has cancer and the test is positive - the top path. We can quickly calculate its probability:\n",
        "\n",
        "$$\\mathbb{P}(\\text{cancer }\\textit{and}\\text{ positive}) = 1\\% \\times 80 \\% = \\frac{1\\times 80}{100 \\times 100} = 0.8 \\%$$\n",
        "\n",
        "So putting it all together we get:\n",
        "\n",
        "$$\\mathbb{P}(cancer | positive) = \\frac{0.8\\%}{10.304\\%} \\approx 7.8\\%$$\n",
        "\n",
        "That is a very non-intuitive result but by the way that we worked it out I hope I can convince you that it is correct! Also what is the intriguing notation that I have just used? $\\mathbb{P}(A | B)$ means the probability of A *given* or *conditional on* B. That is having learned that B happened what can we say about A?\n",
        "\n",
        "The more general rule we just derived is the definition for conditional probabilities:\n",
        "\n",
        "$$\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A \\textit{ and } B)}{\\mathbb{P}(B)}$$\n",
        "\n",
        "There is nothing special about $A$ and $B$ so we can switch them around to get:\n",
        "\n",
        "$$\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(B \\textit{ and } A)}{\\mathbb{P}(A)}$$\n",
        "\n",
        "Using the two equations we get:\n",
        "\n",
        "$$\\mathbb{P}(B|A)\\times \\mathbb{P}(A) = \\mathbb{P}(B \\textit{ and } A) = \\mathbb{P}(A|B)\\times \\mathbb{P}(B)$$\n",
        "\n",
        "Because $B \\textit{ and } A$ is the same as $A \\textit{ and } B$. And from it we have a very famous equation known as a Bayes rule:\n",
        "\n",
        "$$\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(B|A)\\times \\mathbb{P}(A)}{\\mathbb{P}(B)}$$\n",
        "\n",
        "We will use it extensively in the 3rd notebook. For now you can think of it as saying that for some things - context is everything! That is for some probability analysis you have to take its surounding information into account. For example, you can estimate a probability that there is a tree growing in a given square of space. It is simple - take all the trees on earth and divite by earths area. But your estimate would be much more accurate if you knew that the square happens to lie in the Amazon forest and used it. \n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMGdey6A5K2N",
        "colab_type": "text"
      },
      "source": [
        "Here are some probability puzzles that you can use your newly acquired knowledge onto! There is even a way to check your answer - enter it in the right variable and run the code.\n",
        "\n",
        "**Exercise 1.5** My aunt has two children. One of those children is a girl. What is the probability that the other is a boy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9z9HTie6B8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = # enter your answer here as a fraction. E.g. 13/21\n",
        "if hash(answer) == 1537228672809129216:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Incorrect. Try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qUGSdjQ6uwB",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.6** Two production lines produce the same part. Line 1 produces 1,000 parts per week of which 100 are defective. Line 2 produces 2,000 parts per week of which 150 are defective. If you choose a part randomly from the stock what is the probability it is defective? If it is defective what is the probability it was produced by line 1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SITG8hnB7sVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = # enter your answer here as a fraction. E.g. 13/21\n",
        "if hash(answer) == 922337203685477632:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Incorrect. Try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewgsRSHK8wrc",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.7** Economic mobility is often measured by splitting the population into five equal brackets, and measuring the chance of moving between brackets. In a perfectly mobile economy, where everyone has equal chance of reaching any quintile, what fraction of people are expected to move by more than one quintile?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4x4mgWw9HuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = # enter your answer here as a fraction. E.g. 13/21\n",
        "if hash(answer) == 1106804644422573056:\n",
        "  print(\"Correct!\")\n",
        "else:\n",
        "  print(\"Incorrect. Try again!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NDJHGqY4GgT",
        "colab_type": "text"
      },
      "source": [
        "## Random Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh75RV2dkQ0a",
        "colab_type": "text"
      },
      "source": [
        "Another short and sweet topic we need to understand before diving into Data Sciency calculations is Random Variables. Simply speaking a random variable is a function that can return a different result each time. Here is a simple random variable - a function that returns a random number between 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSheRx6Hk6nJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1fd3e5d-c3da-4ec4-ac3d-7eafe38cd778"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def x():\n",
        "  return np.random.uniform()\n",
        "\n",
        "print(\"sample of X: \", x())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample of X:  0.4576667219228304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw99NtWflHl8",
        "colab_type": "text"
      },
      "source": [
        "In this section we will develop a simple \"theory\" of random variable - how to specify them, how use them. And we will use random variables all thoughout this course and try to capture the randomness that is present in every real world data set.\n",
        "\n",
        "In mathematics notation, we denote random variable by a capital letter and we specify how we got it. In this case, the random variable is $X$ and we got it by taking a sample from a uniform distribution with range 0 to 1. This has a handy notation: $X \\sim U[0;1]$. \n",
        "\n",
        "We can use one random variable to generate another:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KvgsWeSnxm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0684608-82a7-4178-ddd0-2b8caba8b779"
      },
      "source": [
        "def y():\n",
        "  if x() <= 0.3:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "print(\"sample of Y: \", y())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample of Y:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvh_y477n8k8",
        "colab_type": "text"
      },
      "source": [
        "So to decribe Y we would write: $Y = 1_{X > 0.3}$. Notice that X figures in this expression. Notation: the expression $1_{cond}$ is $1$ when $cond$ is true and $0$ otherwise. This notation is known as an indicator function and can save up a lot of space.\n",
        "\n",
        "An important thing we can say about a random variable is its probability mass or density function. If the random variable is continous - that means it can take values over an interval - we use the word \"density\", if it is discrete - the values are concrete points - we use the word \"mass\". That is the only difference and usually not that important. We usually denote this function by:\n",
        "$Pr_X(X = x)$ or just $Pr_X(x)$. Roughly speaking, it is the probability of obseving the specified value of x. \n",
        "\n",
        "To find probability mass function for our random variable $Y$ we need to consider two possible values - $1$ and $0$. We can convince ourselfs that the densities are:\n",
        "\n",
        "$$Pr_Y(Y = 1) = 0.3$$\n",
        "$$Pr_Y(Y = 0) = 0.7$$\n",
        "\n",
        "If we want to use our newly learnt indicator function notation we can simplify it to:\n",
        "\n",
        "$$Pr_Y(Y = y) = 0.7 - 0.4\\times 1_{y = 1}$$\n",
        "\n",
        "This was easy! In a more difficult case we can see the probability density with computation. It is enough to take a lot of samples from $Y$ and then calculate the frequency of each value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_QiTtY4q5WP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "66be9b97-f25b-47e9-fec9-115b36f2e8a8"
      },
      "source": [
        "y_samples = [y() for _ in range(10000)]\n",
        "# find unique values in the sample and their counts\n",
        "values, count = np.unique(y_samples, return_counts = True)\n",
        "# divide by the total number of samples to get frequency \n",
        "freq = count/np.sum(count)\n",
        "\n",
        "print(values, freq)\n",
        "\n",
        "# Generate a plot for illustration\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(values, freq, width=0.8)\n",
        "ax.set_xticks([0, 1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1] [0.6946 0.3054]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIcKi8evsINA",
        "colab_type": "text"
      },
      "source": [
        "While the values are exactly the one we got, they are very close!\n",
        "\n",
        "Note an important property the probability masses must sum to one.\n",
        "\n",
        "It is harder to find probability density for continous random variables. What would you say is the probability of: $Pr_X(X = 0.34859681289)$? It is very, very, very unilike because there are (theoretically) infinitely many values in the interval $[0;1]$. So our counting unique values method will not work. To find exact Probability density we would need calculus but that is outside the scope of this course. The trick we will use instead are histograms. Histograms work by counting all the samples in a specific intervals. So we are finding the frequency of a sample belonging to a specific interval. The smaller the intervals the closer we get to the true density! Let's see it in action "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcbXyCVuUBP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "57625986-631c-4ac5-cf89-34eb7dfea948"
      },
      "source": [
        "x_samples = [x() for _ in range(100000)]\n",
        "fig, ax = plt.subplots()\n",
        "ax.hist(x_samples, bins=np.linspace(0, 1, 30), density=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiXabCTpurAh",
        "colab_type": "text"
      },
      "source": [
        "This plot might not be that exciting as the probability of getting any particular value is the same. Do not worry if is appears that the probabilities do not sum to $1$ - they do when the bins become smaller and smaller. What is ebcouraging that our plot alings with the mathematical result that the probability density of uniform distribution $Z \\sim U[a;b]$ is:\n",
        "$$ Pr_Z(z) = \\frac{1_{z\\in[a;b]}}{b-a}$$\n",
        "In our case:\n",
        "$$ Pr_X(x) = \\frac{1_{x\\in[a;b]}}{1-0} = 1_{x\\in[a;b]}$$\n",
        "\n",
        "You can always check out the exact probability density function for a distribution in its Wikipedia page!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EO00w9vv7En",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.8**  \n",
        "\n",
        "a) Create a function for a random variable $X$ which represents the total number of heads when flipping a fair coin 20 times.\n",
        "\n",
        "b) Plot the probability mass function for $X$\n",
        "\n",
        "c) On the same plot, plot the theoretical probability mass function from this [Wikipedia page](https://en.wikipedia.org/wiki/Binomial_distribution). You can find the function of the right hand side under \"pmf\" section. Be careful to identify $n, p$ and to only take the function samples at whole number values!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rjOMPvyxRP3",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.9** \n",
        "\n",
        "Plot the probability mass function for [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) taking samples from `np.random.poisson`. On the same figure, plot the theoretical probability mass function as well. The possible values, even though, discrete are potentially infinite, so it is enough to plot the distribution for the first 30 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-1cJgG-yAyS",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.10**\n",
        "Plot the probability density function using histograms for $Normal(\\mu = 0,\\sigma^2 = 1)$ [distribution](https://en.wikipedia.org/wiki/Normal_distribution). You can sample it using `np.random.normal`. If you feel like it, add in a plot for theoretical density as well!"
      ]
    }
  ]
}